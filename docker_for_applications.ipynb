{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f8298d2",
   "metadata": {},
   "source": [
    "### Docker for Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151c69ea",
   "metadata": {},
   "source": [
    "#### Docker voulmes\n",
    "* There are three types of docker volumes\n",
    "  + tmpfs mount\n",
    "    + used to store sensitive data\n",
    "    + temporary storage\n",
    "      + data stored in memory\n",
    "  + named or anonymous volume\n",
    "    + managed by docker by docker cli\n",
    "    + `docker volume create [name of volume]`\n",
    "    + `docker run --volume code-volume:/app`\n",
    "      + if volume exists, it will be mounted, otherwise, a new volume is created\n",
    "    + docker cli for named volume\n",
    "      + docker volume ls\n",
    "    + advantages\n",
    "      + volume is a managed object\n",
    "      + isolated from other host activity\n",
    "      + easy to identify and backup\n",
    "      + better performance when sing docker desktop\n",
    "        + volume is stored in linux virtual machine rather than local system\n",
    "    + disadvantage\n",
    "      + owned by root user (must run docker as root user), which is not a good practice and should be avoided\n",
    "  + bind mount directory inside docker to \n",
    "    + arbitary directory from host \n",
    "    + changes reflected on host\n",
    "    + `docker run --volume /path/on/host:/path/in/container` (path must be absolut path)\n",
    "    + not have to be root user\n",
    "    + must have a docker container to run\n",
    "    + must consider user and group id mismatch when using bind mounts\n",
    "      + the user on local host has a specific user id and group id (uid 1000, gid: 1000)\n",
    "      + for bind mounts, the user inside docker is root (uid:0, gid: 0)\n",
    "        + when you create files or folders inside the docker, the corresponding files on local host can not be written/removed\n",
    "          + these files/directories now belong to root\n",
    "      + solution 1: create the corresponding uid and gid inside docker file\n",
    "        + `RUN groupadd -r --gid 1000 user \\\n",
    "          && useradd -r --uid 1000 -g user user`\n",
    "        + whe run docker then use\n",
    "        `docker run --volume /src --user user myapp touch /src/created_in_container`\n",
    "      + solution 2\n",
    "        + similar to solution 1, instead of creating group and user id by RUN shell script with hard coded ids, using ARG\n",
    "       \n",
    "       ```yaml\n",
    "        FROM debian\n",
    "        \n",
    "        ARG UID=1000\n",
    "        ARG GID=1000\n",
    "        RUN groupadd -r --gid &#36;   GID user \\\n",
    "         &&   useradd -r --uid &#36; UID -g user user\n",
    "         \n",
    "         ```\n",
    "         \n",
    "         In terminal, run\n",
    "         `docker build --build-arg UID=1001 --build-arg GID=1001 -t myapp .`\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2437654",
   "metadata": {},
   "source": [
    "#### A use case of using multi-stage builds\n",
    "* with compiled programming languages\n",
    "  + increased complexity\n",
    "    + not trivial to code and hot reload with a bind mount as in interpretor languages\n",
    "  + larger image size\n",
    "    + development tools captured inside the container image, which is not needed after compilation to exe files\n",
    "* solution: builder pattern\n",
    "  + split the build step sequence from the run step sequence, wth separate Dockerfiles for each task \n",
    "  + we need to use bind mount to refer to the files/directories in the build stage when build the run docker\n",
    "* multi-stage docker (put everything in the same docker with different stages using FROM)\n",
    "\n",
    "    ```yaml\n",
    "      FROM node:14 AS builder\n",
    "      WORKDIR /deps\n",
    "      COPY . .\n",
    "      RUN npm install\n",
    "      \n",
    "      FROM gcr.io/distroless/nodejs\n",
    "      COPY --from=builder /deps /app\n",
    "      WORKDIR /app\n",
    "      CMD [\"server.js\"]\n",
    "      \n",
    "    ```  \n",
    "* for multi-stage docker, you can define to which stage the docker build command should execute and ignore stages after the specified stage\n",
    "  + the target stage and predecessors are included in the build\n",
    "  `docker build -t app-builder --target builder .`\n",
    "  + samller image sizes attained by selective inclusion of content\n",
    "* constructing a multi-stage Dockerfile\n",
    "```yaml\n",
    "# base stage\n",
    "FROM golang:1.16 AS base\n",
    "# lint stage\n",
    "FROM base AS lint\n",
    "COPY golangci-lint /go/bin/\n",
    "WORKDIR /app\n",
    "CMD[\"golangci-lint\", \"run\"]\n",
    "# build stage\n",
    "FROM base as build\n",
    "WORKDIR /app\n",
    "COPY go.??? ./\n",
    "RUN go mod download\n",
    "COPY *.go ./\n",
    "RUN go build -o mini .\n",
    "# execution stage\n",
    "FROM alpine:3\n",
    "COPY --from=build /app/mini /\n",
    "ENTRYPOINT [\"./mini\"]\n",
    "```\n",
    "\n",
    "* An image used only for linting can be built using the --target option\n",
    "  + `docker build -t mini-lint:1.0 --target lint .`\n",
    "  + the built docker image can then be used to lint the code using a bind mount        \n",
    "  `docker run -it --rm -v $(pwd):/app mini-lint:1.0`  \n",
    "    + CMD will be executed to lint the code in current folder of the host, which is mapped to /app inside docker\n",
    "    $\n",
    "* one problem of docker building process is that the process is linear\n",
    "  + even though there is no dependency between lint and build, build stage will be on top of lint\n",
    "  + buildkit can find out the dependency such as both build and lint are based on base, and there is no dependency between them\n",
    "    + processes Dockerfile instructions and constructs a directed acyclic graph of depedencies\n",
    "      + non-denpendency steps are build parallel\n",
    "    +provides an optional extended Dockerfile instruction se for more advanced build features\n",
    "    + buildkit is not the default build engine that is used when invoking a container image build\n",
    "    + to enable buildkit, you can \n",
    "      + set the deamon.json file \n",
    "      ```json\n",
    "        {\n",
    "          <snip>\n",
    "          \"features\": {\"buildkit\": true},\n",
    "          <snip>\n",
    "          }\n",
    "       ```\n",
    "       \n",
    "       + for docker desktop, set this from settings\n",
    "       + set DOCKER_BUILDKIT at any vlaue rather than 0 by\n",
    "         `export DOCKER_BUILDKIT=1`\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b58882",
   "metadata": {},
   "source": [
    "#### Oprimization of docker images\n",
    "* anatomy of an image (using docker inspect cli)\n",
    "  + image configuration object (meta data)    \n",
    "    + command of docker run\n",
    "    + port to expose\n",
    "    + workingDir\n",
    "  + RootFS (file system definition for derived containers)\n",
    "    + content layer that make up the filesystem (Layers with an array of SHA)\n",
    "  + the majority of docker instructions arefor adding metadata to image\n",
    "    + what user to use to run a container\n",
    "    + which command or program to execute\n",
    "  + small portion of instructions to create content for the file system in the form of layers\n",
    "    + COPY instruction (recommended if possible)\n",
    "    + ADD instruction (can also apply to remote content copy)\n",
    "    + RUN (executes commands to generate additional image content)\n",
    "      + add utilities\n",
    "      + install app's dependencies\n",
    "      + create a user\n",
    "    + whenever docker build execute COPY, ADD and RUN instructions, a new content layer is added to the image\n",
    "* when a container is created, docker assembles the content in each layer by making a union of the layers in turn to present a homogeneous set of files and directories\n",
    "  + the contents are read only\n",
    "  + enable to build images from other images\n",
    "  + to write to the docker, docker adds a final layer on top of layers on image\n",
    "    + unique, temporary, writeable layer for every container instance\n",
    "      + not part of the image and is removed when container is removed\n",
    "      + if container need to create a new directory, it is created in this layer\n",
    "      + to alter a content in the previous layer, it copy the content to the final layer (copy on write)\n",
    "      + to delete a content, it is removed from the union of the content by a technique called whiteout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d646265c",
   "metadata": {},
   "source": [
    "#### Consolidate RUN command together to reduce docker layers\n",
    "* to install packages and yarn package management package, we first need to install utilities\n",
    "  + ```shell\n",
    "    RUN apt-get update\n",
    "    RUN apt-get install -y \\\n",
    "         curl              \\  # needed to retrieve pgp keys\n",
    "         ca-certificates   \\  # to make curl wrork securely\n",
    "         gnupg                # add retrieve keys to keyring\n",
    "    ``` \n",
    "  + these content are temporary content. We don't need them after the service\n",
    "    + it makes the image larger than it needs to be \n",
    "    + we want to build lean, secure, and efficient docker images\n",
    "    + we need to find a way to remove it once it served its purpose\n",
    "  + how can we remove this?\n",
    "    + solution 1:\n",
    "    + ```shell\n",
    "    RUN apt-get update\n",
    "    RUN apt-get install -y \\\n",
    "         curl              \\  # needed to retrieve pgp keys\n",
    "         ca-certificates   \\  # to make curl wrork securely\n",
    "         gnupg                # add retrieve keys to keyring\n",
    "         \n",
    "    RUN apt-get update\n",
    "    \n",
    "    RUN apt-get install -y  \\\n",
    "         nodejs             \\\n",
    "         yarn\n",
    "         \n",
    "    RUN apt-get purge -y curl ca-certificates gnugp  \n",
    "    \n",
    "    ``` \n",
    "   + if we do this, the temporary contents are still there and the image size will not be reduced, may be even bigger\n",
    "     + the contents are not deleted from the previous layer. They are removed from the union of layer\n",
    "     + you add extra content to remove the contents from union\n",
    "   + what we can do is to consolidate all the run commands together into one layer  \n",
    "   + ```shell\n",
    "    RUN apt-get update && \\\n",
    "        apt-get install -y \\\n",
    "         curl              \\  # needed to retrieve pgp keys\n",
    "         ca-certificates   \\  # to make curl wrork securely\n",
    "         gnupg           && \\ # add retrieve keys to keyring\n",
    "         \n",
    "       apt-get update    && \\\n",
    "    \n",
    "       apt-get install -y  \\\n",
    "         nodejs             \\\n",
    "         yarn           && \\\n",
    "         \n",
    "      apt-get purge -y curl ca-certificates gnugp  \n",
    "      ```\n",
    "    + disadvantage is that if we change any line of the code, the entire block will have to be re-executed \n",
    "      + we can not utilize cache when building the image     \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6020d06d",
   "metadata": {},
   "source": [
    "#### using build cache\n",
    "* docker uses a local cache of image build steps\n",
    "  + careful placement of dockerfile instructions can maximize cache hits\n",
    "  + docker build process:\n",
    "    + each Dockerfile instruction processed druing a build results in an intermediary image as part of build cache\n",
    "    + these images are created by committing containers created from the image associated with preceding instructions\n",
    "    + images reference their parent image and create an implicit chain of images representing a sequence of instructions\n",
    "  + docker build caches each imtermideiate layers, which will be checked for the later build processes\n",
    "    + if a layer is found cached, it will directly use the cached intermediate image and build the following images\n",
    "    + this will affect the build time\n",
    "* the following instructions will invalidate the cache\n",
    "  + instruction change\n",
    "    + adding, removing, or altering an instruction\n",
    "  + checksum check change  \n",
    "    + content change in build context (copy o add to the build context)\n",
    "  + command output will not be checked\n",
    "    + consequences of command execution are not checked\n",
    "  + original\n",
    "  ```yaml\n",
    "  WORKDIR /app\n",
    "  COPY . .\n",
    "  RUN yarn install\n",
    "  ```\n",
    "  + change to\n",
    "  ```\n",
    "  WORKDIR /app\n",
    "  COPY package.json yarn.lock ./\n",
    "  RUN yarn install\n",
    "  COPY spec src ./\n",
    "  ```\n",
    "  + by this change, you don't have to copy package.json, yarn.lock and reinstall yarn each time when you change source code\n",
    "    + the images before COPY spec src ./ is cached in your local host and can be directly used for docker building\n",
    "  + tips:\n",
    "    + analyze dependencies between Dockefile instructions to determine ordering constraints\n",
    "    + order Dockerfile instructions according to the frequency of change\n",
    "      + less frequent first, more frequent last\n",
    "    + where it's beneficial, split COPY Dockerfile instructions that copy content from the build context  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a9d0a",
   "metadata": {},
   "source": [
    "#### utilizing multi-stage Dockerfiles to optimize size of image\n",
    "* By separating consolidated command lines to separate RUN commands, we created multi-layers in docker image\n",
    "  + this will increase the size of the image\n",
    "  + but will improve the building process since most of commands corresponding cached layers\n",
    "  + if this is not the final image in the production, the image size is not a concern\n",
    "    + we sacrifice size for speed and efficiency\n",
    "* we can use multi-stage Dockerfiles to control the final image size \n",
    "  + we are free to use multi-layer dockers as intermediate/previous stage images\n",
    "    + this can fully take advantage of cached image     \n",
    "  + just leave the temporary content resides in a previous stage\n",
    "    + we don't need to remove/delete temporary content since we will not use them in multi-stage Dockerfiles\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cd5317",
   "metadata": {},
   "source": [
    "#### How docker handle different environments\n",
    "* application configuration\n",
    "  + everything that is likely to vary between deploys (staging, production, developer evinronments etc.)\n",
    "  + principle of separating code and config\n",
    "    + don't define configuration as constants in the applications's source code\n",
    "    + store cofig in enviornment variables\n",
    "      + easy to manage many instances running in different environments\n",
    "      + no leakage of sensitive information hard-coded in software applications\n",
    "      + straightforward onaboarding of new envrionments to host software apps\n",
    "      + no need to re-test software apps due to chagnes to the configuration\n",
    "      + config defined in environment variables are agnostic to languages and os\n",
    "* define environment varaible in docker by env\n",
    "  + ```yaml\n",
    "    \n",
    "    ENV REDIS_HOST \"redis_server\"  # not recommended\n",
    "    ENV REDIS_HOST=\"redis_server\" REDIS_PORT=6379  # recommended\n",
    "    ENV REDIS_HOST=\"redis_server\" \\\n",
    "        REDIS_PORT=6379\n",
    "   \n",
    "   ```    \n",
    "* define environment variables in .env file and use it \n",
    "`docker run --rm --env-file file/path/to/redis.env`\n",
    "\n",
    "* don't use environment variable to save sensitive inforamtion\n",
    "\n",
    "* combine ARG and ENV in Dockerfile\n",
    "  + ```ymal\n",
    "    ARG NODE_ENV\n",
    "    ENV NODE_ENV \"&#36;{NODE_ENV:-production}\"\n",
    "   ``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffda0da",
   "metadata": {},
   "source": [
    "#### Application logging configuration in docker\n",
    "* logs are designed to report on events during execution\n",
    "  + programmers code log writing within their source code for reporting\n",
    "  + log messages are provided as output during program execution for debugging\n",
    "* docker cpatures, and stores output written to the STDOUT and STDERR streams\n",
    "  + therefore, write logs to the standout\n",
    "  + in case a app such as nginx write logs to its specific log fiels, we use symbolic links to lead them to stdout\n",
    "    + in Dockerfile, we run\n",
    "    ```shell\n",
    "    RUN ln -sf /dev/stdout /var/log/ngnix/access.log && \\\n",
    "          ln -sf /dev/stderr /var/log/nginx/error.log\n",
    "    ```\n",
    "* logging drivers (https://git.io/JOPzr)\n",
    "  + docker has json-file logging drive as the default logging drive\n",
    "    + store logs locally in JSON format by docker daemon\n",
    "  + local\n",
    "    + flexible and more performant file-based logging solution\n",
    "  + journald\n",
    "    + logs sent to journald service running on the Docker host\n",
    "  + log-driver is configured in the file daemon.json\n",
    "    + \n",
    "      ```json\n",
    "    \"log-driver\": \"local\"\n",
    "    \"log-opts\": {\n",
    "        \"max-size\": \"10m\",\n",
    "        \"max-file\": \"6\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "  + we can also override system configuration for individual containers\n",
    "    `docker run -it --name todo --log-dirver local --log-opt max-file=3 todo`\n",
    "  + to find out which logging drive we use for a specific docker, we can use\n",
    "    `docker inspect --format '{{.HostConfig.LogConfig.Type}' todo`\n",
    "* to see logs, using\n",
    "  `docker logs container_id/name`\n",
    "  + other tags to customize output\n",
    "    + --details\n",
    "    + --follow (see logs real time)\n",
    "    + --tail\n",
    "    + --since (--since 5 m)\n",
    "    + --until\n",
    "    + --timestamps\n",
    "* docker config example\n",
    "  + check system log config for docker\n",
    "  `docker info -f '{{.LoggingDriver}}'`\n",
    "  + change it to local driver\n",
    "    + find dawmon.json or access it from docker desktop         \n",
    "    add a new line `\"log-driver\": \"local\"`\n",
    "* when docker container is removed, logs are removed unless using journald logging driver\n",
    "  `dufo journalctl -f CONTAINER_NAME=todo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c0dff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
